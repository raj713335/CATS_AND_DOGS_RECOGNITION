# -*- coding: utf-8 -*-
"""rock_paper_scissors.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/Course%202%20-%20Part%208%20-%20Lesson%202%20-%20Notebook%20(RockPaperScissors).ipynb
"""

"""!wget - -no - check - certificate \
    https: // storage.googleapis.com / laurencemoroney - blog.appspot.com / rps.zip \
              - O / tmp / rps.zip

!wget - -no - check - certificate \
    https: // storage.googleapis.com / laurencemoroney - blog.appspot.com / rps - test - set.zip \
              - O / tmp / rps - test - set.zip

import os
import zipfile

local_zip = '/tmp/rps.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/tmp/')
zip_ref.close()

local_zip = '/tmp/rps-test-set.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/tmp/')
zip_ref.close()"""

"""import os


os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

dir_path = os.path.dirname(os.path.realpath("Image_Training.py"))
dir_path=dir_path.replace("\\","/")

print(dir_path)

#rock_dir = os.path.join('/tmp/rps/rock')
#paper_dir = os.path.join('/tmp/rps/paper')
#scissors_dir = os.path.join('/tmp/rps/scissors')

#M1256 = "".join(dir_path,'/Bolt Images (New Folder)/Bolt 1 - M12 5.6 grade')
#M2010 = os.path.join(dir_path,'/Bolt Images (New Folder)/Bolt 2 - M20 10.9')
#M1488 = os.path.join(dir_path,'/Bolt Images (New Folder)/Bolt 3 - M14 8.8')

M1256=dir_path+'/Bolt Images (New Folder)/Bolt 1 - M12 5.6 grade'
M2010 = dir_path+'/Bolt Images (New Folder)/Bolt 2 - M20 10.9'
M1488 = dir_path+'/Bolt Images (New Folder)/Bolt 3 - M14 8.8'
M1256TEMP=dir_path+'/Bolt Images (New Folder)/M12 5.6 (24Jun2019)'

print(M1256)


print('total training M12 5.6 grade images:', len(os.listdir(M1256)))
print('total training M20 10.9 images:', len(os.listdir(M2010)))
print('total training M14 8.8 images:', len(os.listdir(M1488)))
print('total training M1256TEMP images:', len(os.listdir(M1256TEMP)))

rock_files = os.listdir(M1256)
print(rock_files[:])

paper_files = os.listdir(M2010)
print(paper_files[:])

scissors_files = os.listdir(M1488)
print(scissors_files[:])

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

import matplotlib.pyplot as plt
import matplotlib.image as mpimg

pic_index = 2

next_rock = [os.path.join(M1256, fname)
             for fname in rock_files[pic_index - 2:pic_index]]
next_paper = [os.path.join(M2010, fname)
              for fname in paper_files[pic_index - 2:pic_index]]
next_scissors = [os.path.join(M1488, fname)
                 for fname in scissors_files[pic_index - 2:pic_index]]

for i, img_path in enumerate(next_rock + next_paper + next_scissors):
    # print(img_path)
    img = mpimg.imread(img_path)
    plt.imshow(img)
    plt.axis('Off')
    plt.show()

import tensorflow as tf
import keras_preprocessing
from keras_preprocessing import image
from keras_preprocessing.image import ImageDataGenerator

#TRAINING_DIR = "/tmp/rps/"
TRAINING_DIR=dir_path+'/TRAIN_DIR'
training_datagen = ImageDataGenerator(
    rescale=1. / 255,
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest')

#VALIDATION_DIR = "/tmp/rps-test-set/"

VALIDATION_DIR = dir_path+"/VALIDATION_DIR"

validation_datagen = ImageDataGenerator(rescale=1. / 255)

train_generator = training_datagen.flow_from_directory(
    TRAINING_DIR,
    target_size=(640, 480),
    class_mode='categorical'
)
print(train_generator)

validation_generator = validation_datagen.flow_from_directory(
    VALIDATION_DIR,
    target_size=(640, 480),
    class_mode='categorical'
)

model = tf.keras.models.Sequential([
    # Note the input shape is the desired size of the image 150x150 with 3 bytes color
    # This is the first convolution
    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(640, 480, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    # The second convolution
    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2),
    # The third convolution
    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2),
    # The fourth convolution
    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2),
    # Flatten the results to feed into a DNN
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dropout(0.5),
    # 512 neuron hidden layer
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(4, activation='softmax')
])

model.summary()

model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])

history = model.fit_generator(train_generator, epochs=25, validation_data=validation_generator, verbose=1)

model.save("rps.h5")

import matplotlib.pyplot as plt

acc = history.history['acc']
val_acc = history.history['val_acc']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

plt.plot(epochs, acc, 'r', label='Training accuracy')
plt.plot(epochs, val_acc, 'b', label='Validation accuracy')
plt.title('Training and validation accuracy')
plt.legend(loc=0)
plt.figure()

plt.show()"""


"""

import numpy as np
#from google.colab import files
from keras.preprocessing import image
from keras.models import load_model

model = load_model("rps.h5")

#uploaded = files.upload()


# predicting images
path = 'test.jpg'
img = image.load_img(path, target_size=(640, 480))
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)

images = np.vstack([x])
classes = model.predict(images, batch_size=10)

print(classes)

"""

# USAGE
# python label_multi_images.py --model model/VGG19_20190626_112141_model_weights.h5

# import the necessary packages
import os

os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
import tensorflow as tf

tf.logging.set_verbosity(tf.logging.ERROR)
from keras.preprocessing.image import img_to_array
from keras.models import load_model
from imutils import build_montages
from imutils import paths
import numpy as np
import argparse
import random
import cv2
import datetime
import keras.models
import tensorflow as tf
from keras.preprocessing import image



def lable_image(model, classes):
    dt = datetime.datetime.now()
    # get working directories
    wdir = os.path.dirname(__file__)
    print(wdir)
    images = os.path.join(wdir, 'results', 'input')
    print(images)
    processed = os.path.join(wdir, 'results', 'output', dt.strftime("%Y%m%d_%H%M%S"))

    # load the pre-trained network


    model = tf.keras.models.Sequential([
        # Note the input shape is the desired size of the image 150x150 with 3 bytes color
        # This is the first convolution
        tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(640, 480, 3)),
        tf.keras.layers.MaxPooling2D(2, 2),
        # The second convolution
        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
        tf.keras.layers.MaxPooling2D(2, 2),
        # The third convolution
        tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),
        tf.keras.layers.MaxPooling2D(2, 2),
        # The fourth convolution
        tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),
        tf.keras.layers.MaxPooling2D(2, 2),
        # Flatten the results to feed into a DNN
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dropout(0.5),
        # 512 neuron hidden layer
        tf.keras.layers.Dense(512, activation='relu'),
        tf.keras.layers.Dense(4, activation='softmax')
    ])





    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])

    model.load_weights('rps.h5')

    import numpy as np
    from keras.preprocessing import image
    from keras.models import load_model

    #model = load_model("rps.h5")





    #new_predictions = model.predict('text.jpg')

    #print(new_predictions)

    #path = 'C:/Users/c0mcl3s/PycharmProjects/OPEN_CV/OPEN CV/results/input'
    #img = image.load_img(path, target_size=(640, 480))
    x = image.img_to_array('text.jpg')
    x = np.expand_dims(x, axis=0)

    images = np.vstack([x])
    classes = model.predict(images, batch_size=10)

    print(classes)

    """# grab all image paths in the input directory and randomly sample them
    imagePaths = list(paths.list_images(images))
    print(imagePaths)
    random.shuffle(imagePaths)
    # imagePaths = imagePaths[:16]

    # initialize our list of results
    results = []
    # loop over our sampled image paths
    for p in imagePaths:
        # load our original input image
        orig = cv2.imread(p)

        # pre-process our image by converting it from BGR to RGB channel
        # ordering (since our Keras mdoel was trained on RGB ordering),
        # resize it to 256 X 256 pixels, and then scale the pixel intensities
        # to the range [0, 1]
        image = cv2.cvtColor(orig, cv2.COLOR_BGR2RGB)
        image = cv2.resize(image, (480, 640))
        image = image.astype("float") / 255.0
        print(cv2.imshow(image,1))

        # order channel dimensions (channels-first or channels-last)
        # depending on our Keras backend, then add a batch dimension to
        # the image
        image = img_to_array(image)
        image = np.expand_dims(image, axis=0)

        # make predictions on the input image
        pred = model.predict(image)
        indx = pred.argmax(axis=1)[0]
        label = classes[indx][0]
        torque = classes[indx][1]

        # resize our original input (so we can better visualize it) and
        # then draw the label on the image
        orig = cv2.resize(orig, (256, 256))
        color = (131, 15, 25)
        msg = "{}: {}".format(label, torque)
        cv2.putText(orig, msg, (3, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

        # add the output image to our list of results
        results.append(orig)

    # move image to processed folder
    # F.moveAllFilesinDir(images, processed)

    # create a montage using 128x128 "tiles" with 4 rows and 4 columns
    row = int(np.ceil(len(results) / 3))
    col = 3
    montage = build_montages(results, (256, 256), (col, row))[0]

    # show/write the output montage
    # cv2.imshow("Results", montage)
    # cv2.waitKey(0)
    cv2.imwrite(os.path.join(processed, 'result.jpg'), montage)"""


if __name__ == '__main__':
    # construct the argument parser and parse the arguments
    """ap = argparse.ArgumentParser()
    ap.add_argument("-m", "--model", required=True,
                    help="path to pre-trained model")
    args = vars(ap.parse_args())"""

    classes = {0: ['M12_05_06', '55 Nm'], 1: ['M14_08_08', '87 Nm'], 2: ['M20_10_09', '387 Nm'],3:['lol','678 Nm']}

    lable_image('C/Users/c0mcl3s/PycharmProjects/OPEN_CV/OPEN CV', classes)


